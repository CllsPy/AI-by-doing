{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1JVvF6xzE9Fw7tyEUNPDjPCu-EctJ2N1_",
      "authorship_tag": "ABX9TyOdLZG+WY6W2rDiGiwYtCD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CllsPy/AI-by-doing/blob/main/ldaIF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOw3P9UzxWoP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "\n",
        "!pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "UYZ_x1cMxexA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "M9VpT1fBxflp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "\n",
        "#Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "#spacy\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#vis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "tqnGfOMRxpmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = stopwords.words(\"portuguese\")\n",
        "#stopwords"
      ],
      "metadata": {
        "id": "OfmwsAenxtka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/table.csv')\n",
        "data = data.rename(columns={\"TÃ­tulo da Proposta\": \"Text\"})\n",
        "data"
      ],
      "metadata": {
        "id": "5vKitYU9xwmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"pt_core_news_lg\")"
      ],
      "metadata": {
        "id": "o-n0lAVYykzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis # package to interpret the topics in a topic model\n",
        "import pyLDAvis.gensim_models # python library for the interactive topic modeling visualization\n",
        "import pickle # for html export\n",
        "import pandas as pd # for data processing\n",
        "import os # for setting working directory\n",
        "import re # regular expression library\n",
        "from wordcloud import WordCloud # for generating word clouds\n",
        "import gensim # open-source library for unsupervised topic modeling, document indexing\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk # python tool kit for NLP\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords # for removing stop words\n",
        "import gensim.corpora as corpora # for mapping words to integers\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "E-nlSxG-8l7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Remove punctuation/lower casing\n",
        "#data['text_processed'] = \\\n",
        "data = data['Text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "data"
      ],
      "metadata": {
        "id": "L1rxcOzB8LyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\"\"\"\n",
        "    Functions removing the stopwords\n",
        "\"\"\"\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc))\n",
        "             if word not in stopwords] for doc in texts]\n",
        "\n",
        "data_words = list(sent_to_words(data))#converting them into list\n",
        "\n",
        "data_words = remove_stopwords(data_words)# remove stop words\n",
        "print(data_words[:1][0][:30])"
      ],
      "metadata": {
        "id": "4gJPdYSk8gdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_words\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# Printing the corpus in a numeric form which implies the frequency of the word"
      ],
      "metadata": {
        "id": "-3zfWbfD8r3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "# number of topics\n",
        "num_topics = 10\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "id": "xc_c8da98t4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from pprint import pprint\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "# Assuming you have already preprocessed the data\n",
        "# corpus: the bag-of-words corpus\n",
        "# id2word: the dictionary mapping word IDs to words\n",
        "\n",
        "# Number of topics\n",
        "num_topics = 10\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "\n",
        "# Print the keywords in the topics\n",
        "pprint(lda_model.print_topics())\n",
        "\n",
        "# Get the document-topic distribution\n",
        "doc_lda = lda_model[corpus]\n",
        "\n",
        "# Visualize the topics using pyLDAvis\n",
        "pyLDAvis.enable_notebook()  # Enable for Jupyter Notebooks\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "pyLDAvis.display(vis)\n"
      ],
      "metadata": {
        "id": "rBdhDYRl8vtC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}